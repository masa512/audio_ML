{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "authorship_tag": "ABX9TyOsc1wiR3sqHyf+d6M6lYry",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/masa512/audio_ML/blob/main/basic_audio_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Audio Deep Learning Basics\n",
        "\n",
        "reference : https://pytorch.org/tutorials/intermediate/speech_command_classification_with_torchaudio_tutorial.html\n",
        "\n",
        "the architecture : \n",
        "https://arxiv.org/pdf/1610.00087.pdf"
      ],
      "metadata": {
        "id": "e90cN23q1BS_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataloader generation"
      ],
      "metadata": {
        "id": "Y6Zd9OZw5d-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio \n",
        "import torch\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "renz2hH-1IGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change device to cuda\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "47L1T24v1uRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load classification dataset class and randomly split dataset into 80% Train and 20% Test\n",
        "SC_data = torchaudio.datasets.SPEECHCOMMANDS('.', download=True)\n",
        "\n",
        "# The partitioning\n",
        "N_total = SC_data.__len__()\n",
        "N_train = int(N_total*0.8)\n",
        "N_test = N_total-N_train\n",
        "\n",
        "train_data, test_data = torch.utils.data.random_split(SC_data,[N_train,N_test])\n"
      ],
      "metadata": {
        "id": "3fRjxQYa11CQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We will look at the data content in detail\n",
        "\n",
        "'''\n",
        "train_data\n",
        "\n",
        "1. audio (X)\n",
        "2. Sample rate\n",
        "3. Classification (Y)\n",
        "4. Speaker ID\n",
        "5. Utterance number\n",
        "'''\n",
        "\n",
        "print(train_data[0])\n",
        "#train_data[0]\n",
        "train_data[0]\n",
        "\n",
        "train_data.__len__()\n"
      ],
      "metadata": {
        "id": "NJ224wsL6HbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observe the Data a bit more visually"
      ],
      "metadata": {
        "id": "p_oGixwe_Zsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List file names starting with char and is a folder\n",
        "\n",
        "label_names = [name for name in os.listdir(\"./SpeechCommands/speech_commands_v0.02\") if name[0].isalpha() and os.path.isdir(os.path.join('./SpeechCommands/speech_commands_v0.02',name))]\n",
        "\n",
        "# The number labels for this dataset is shown below\n",
        "print(len(label_names))\n",
        "\n",
        "# Read number of audios per label\n",
        "label_cnt = [len(os.listdir(os.path.join(\"./SpeechCommands/speech_commands_v0.02\",label))) for label in label_names]\n",
        "\n"
      ],
      "metadata": {
        "id": "Te6LJ9vm_rRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the count using pie chart \n",
        "plt.figure(figsize =(10,10))\n",
        "plt.pie(label_cnt,labels = label_names)\n",
        "plt.title('Label Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LxNQvCBHB2M9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Model : M5\n",
        "\n",
        "The model is based on elementary conv network\n"
      ],
      "metadata": {
        "id": "fI5YigpBHK81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class conv_module(nn.Module):\n",
        "  # The chain of 1D Conv -> BN -> Relu\n",
        "\n",
        "  def __init__(self,in_channel,out_channel,kernel_size,stride = 1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv = nn.Conv1d(in_channel, out_channel, kernel_size, stride = 1)\n",
        "    self.bn = nn.BatchNorm1d(out_channel)\n",
        "    self.relu = nn.ReLU()\n",
        "  \n",
        "  def forward(self,x):\n",
        "    x = self.conv(x)\n",
        "    x = self.bn(x)\n",
        "    return self.relu(x)\n",
        "\n",
        "class M5_model(nn.Module):\n",
        "  \n",
        "  def __init__(self,in_channel,base_channel,n_class):\n",
        "    super().__init__()\n",
        "    self.conv1 = conv_module(in_channel,base_channel,kernel_size=80, stride = 16)\n",
        "    self.conv2 = conv_module(base_channel,base_channel,kernel_size=3)\n",
        "    self.conv3 = conv_module(base_channel,2 * base_channel,kernel_size=3)\n",
        "    self.conv4 = conv_module(2 * base_channel,2 * base_channel,kernel_size=3)\n",
        "\n",
        "    self.pool = nn.MaxPool1d(4)\n",
        "    self.fc1 = nn.Linear(2 * base_channel, n_class)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    x = self.conv1(x)\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = self.conv4(x)\n",
        "    x = self.pool(x)\n",
        "\n",
        "    # Compress the signal dimension to length 1 using Average pooling\n",
        "    x = nn.functional.avg_pool1d(x,x.shape[-1]) # Last dim has length 1\n",
        "    # We then shuffle the dimensions so that channel dimension comes last\n",
        "    x = x.permute(0,2,1)\n",
        "    # Then we do a last FC to make the channel dimenson output the n_class\n",
        "    x = self.fc1(x)\n",
        "\n",
        "    # Do a softmax over the channel dimension (last dim)\n",
        "    x = nn.functional.log_softmax(x,dim=-1)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "9P9cru31I3GX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "L712WIGvzXjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test code with length 16000\n",
        "\n",
        "x = torch.randn(1, 1, 13000)\n",
        "model = M5_model(1,32,35)\n",
        "y = model(x)\n",
        "print(y.shape)\n",
        "\n",
        "print(torch.argmax(y))"
      ],
      "metadata": {
        "id": "g7xYqZzkzV7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some useful function for accessing word or index from the other information\n",
        "\n"
      ],
      "metadata": {
        "id": "8mN0dOvY2o98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word2idx(word_list,word):\n",
        "  idx = np.where(np.array(word_list) == word)[0][0]\n",
        "  return idx\n",
        "\n",
        "\n",
        "def idx2word(word_list,idx):\n",
        "  word = word_list[idx]\n",
        "  return word"
      ],
      "metadata": {
        "id": "1W8pBsCi0BGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test word2idx\n",
        "\n",
        "word = 'backward'\n",
        "print(word2idx(label_names,word))\n",
        "\n",
        "#test idx2word\n",
        "print(idx2word(label_names,31))"
      ],
      "metadata": {
        "id": "ySVMM_ru3wcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data transformation function\n",
        "\n",
        "1. Padding to match batch-wise length (Similar to NLP)\n",
        "2. Define collating fn (batch-wise processing function)\n",
        "3. Define the dataloader class using the collating fn\n"
      ],
      "metadata": {
        "id": "P2904FP4MGex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First the padding function\n",
        "\n",
        "def pad_common(batch):\n",
        "\n",
        "  \"\"\"\n",
        "  Input \n",
        "  batch : List of Torch tensors with (Nc,Nt)\n",
        "\n",
        "  Returns\n",
        "  batch : Torch tensor with (Lb, Nc, Nt)\n",
        "  \"\"\"\n",
        "\n",
        "  # We want to transpose our individual data to have dimension (Nt,Nc)\n",
        "\n",
        "  batch = [data.T for data in batch]\n",
        "\n",
        "  # Feed entire list of data into nn.utils.rnn.pad_sequence to act on dim = 0 -> this function returns torch tensor\n",
        "\n",
        "  batch = nn.utils.rnn.pad_sequence(batch, batch_first=True)\n",
        "\n",
        "  # Rearrange from (B, Nt, Nc) to (B, Nc, Nt)\n",
        "\n",
        "  batch = batch.permute(0,2,1)\n",
        "  return batch\n",
        "\n",
        "\n",
        "# Testing for padding\n",
        "\n",
        "a = torch.randn(1,150)\n",
        "b = torch.randn(1,149)\n",
        "c = torch.randn(1,120)\n",
        "\n",
        "batch = [a,b,c]\n",
        "\n",
        "print(pad_common(batch).size())"
      ],
      "metadata": {
        "id": "QnPZWHaE4VBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Then the collating function for batch generator\n",
        "\n",
        "def collate_fn(batch):\n",
        "  \"\"\"\n",
        "  collate function used for dataloader function to define a way the training sequence extracts data batch & target batch\n",
        "\n",
        "  input : \n",
        "  batch (torch tensor with (B,C,L))\n",
        "\n",
        "\n",
        "  returns :\n",
        "  X : Batch of input tensors after preprocessing\n",
        "  Y : Batch of target labels after preprocessing \n",
        "  \"\"\"\n",
        "  \n",
        "  #Initiate X,Y as empty list - we will append our extracted data on here\n",
        "  X,Y = [],[]\n",
        "\n",
        "  for x, _,label, _, _ in batch:\n",
        "\n",
        "    X.append(x)\n",
        "    Y.append(word2idx(label_names,label))\n",
        "  \n",
        "  # Pad sequence using helper function\n",
        "  \n",
        "  X = pad_common(X)\n",
        "\n",
        "  # Generate torch tensor (B,1) for target\n",
        "  Y = torch.tensor(Y)[:,np.newaxis]\n",
        "\n",
        "  return X,Y\n",
        "\n",
        "\n",
        "# Testing function for collating_fn\n",
        "\n",
        "batch = [train_data[i] for i in range(5)]\n",
        "X,Y = collate_fn(batch)\n",
        "\n",
        "print(X.shape)\n",
        "print(Y)"
      ],
      "metadata": {
        "id": "jKxnbLUKRDcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now the train, test dataloaders\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_data,\n",
        "                                           batch_size=256,\n",
        "                                           shuffle=True,\n",
        "                                           collate_fn = collate_fn)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_data,\n",
        "                                           batch_size=256,\n",
        "                                           shuffle=False,\n",
        "                                           drop_last=False,\n",
        "                                           collate_fn = collate_fn)"
      ],
      "metadata": {
        "id": "DHsNI3lcRre8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The optimizer and criterion function\n",
        "\n",
        "1. We will use ADAM optimizer with the parameters given on the pytorch tutorial to relieve the stress\n",
        "\n",
        "2. We will use step-based learning rate decay (constant reduction)\n",
        "\n",
        "3. We will use negative log likelihood function for loss\n",
        "  a) We will use vector of size (B,C) and compare with the one-hot target (B,1) and nn.nll_loss function for gradient descent"
      ],
      "metadata": {
        "id": "Rk70-fZBWFvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The optimizer - Also add the regularization for weights by setting lambda = 0.0001\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.01, weight_decay=0.0001)\n",
        "\n",
        "# The stepLR learning decay scheduler\n",
        "# This means -> Every 20 steps, decrease learning rate by new_lr = old_lr * gamma\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
        "\n",
        "# Also define a criterion funciton\n",
        "criterion = nn.NLLLoss()"
      ],
      "metadata": {
        "id": "6mEMYfbDVo2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finally the Training sequence\n",
        "\n",
        "1. For conciseness, define a single run (single epoch) -> Better for debug"
      ],
      "metadata": {
        "id": "GuUczokTZ17w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training function"
      ],
      "metadata": {
        "id": "KA65-FNSex6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, cur_epoch):\n",
        "\n",
        "  \"\"\"\n",
        "  Single epoch run through the model\n",
        "\n",
        "  Input:\n",
        "  model : Current instance of the trained model so far # PASSED BY REFERENCE\n",
        "  cur_epoch : The current iteration we are on\n",
        "\n",
        "  Return:\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # now model to train mode  \n",
        "  model.train()\n",
        "\n",
        "  # for loop over batches\n",
        "\n",
        "  losses = [] # This is the history of losses for evaluation of average\n",
        "  for X,Y in train_loader:\n",
        "    \n",
        "    optimizer.zero_grad() # Reset to accumulation of gradient\n",
        "\n",
        "    # Send both X and Y to cuda device\n",
        "    X = X.to(device)\n",
        "    Y = Y.to(device)\n",
        "\n",
        "    # Forward pass through model\n",
        "    Yhat = model(X)\n",
        "\n",
        "    # Loss\n",
        "    loss = criterion(Y,Yhat)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    # Backward-pass\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  \n",
        "  print(f'\\nThe training loss for current epoch {cur_epoch} : {sum(losses)/len(losses)}')\n"
      ],
      "metadata": {
        "id": "5Typ6D1pZ5Rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing function\n",
        "\n",
        "The accuracy criterion is the percent correct over testing dataset which we define here too"
      ],
      "metadata": {
        "id": "4ND68ieke0hX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def number_of_correct(pred, target):\n",
        "    # count number of correct predictions\n",
        "    return pred.squeeze().eq(target).sum().item()\n",
        "\n",
        "\n",
        "def get_likely_index(tensor):\n",
        "    # find most likely label index for each element in the batch\n",
        "    return tensor.argmax(dim=-1)\n",
        "\n",
        "sample_rate = 16000\n",
        "new_sample_rate = 8000\n",
        "transform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=new_sample_rate)\n",
        "transform = transform.to(device)\n"
      ],
      "metadata": {
        "id": "2Fn9h1UGcxLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, cur_epoch):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        # apply transform and model on whole batch directly on device\n",
        "        data = transform(data)\n",
        "        output = model(data)\n",
        "\n",
        "        pred = get_likely_index(output)\n",
        "        correct += number_of_correct(pred, target)\n",
        "\n",
        "        # update progress bar\n",
        "        #pbar.update(pbar_update)\n",
        "\n",
        "    print(f\"\\nTest Epoch: {cur_epoch}\\tAccuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)\\n\")"
      ],
      "metadata": {
        "id": "6f3-VDXtMShY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epoch = 2\n",
        "with tqdm(total=n_epoch) as pbar:\n",
        "    for epoch in range(1, n_epoch + 1):\n",
        "        train_model(model, epoch)\n",
        "        test_model(model, epoch)\n",
        "        lr_scheduler.step()"
      ],
      "metadata": {
        "id": "93qIH8i5NJpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vZAinn-4Narv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}